---
title: "Exercise - Regression overview: from Observation to Experiment"
format: html
editor: visual
---

# ------------------------------------------------------------------------------

### Open source data & applied study:

Open access data was utilized for this class exercise from the study (Buntaine et al., 2024):

> "Social Competition Drives Collective Action to Reduce Informal Waste Burning in Uganda"

# ------------------------------------------------------------------------------

### Following along?

In this tutorial I use `this text style` to highlight:

1.  Statistical jargon - E.g., `Ordinary Least Squares (OLS)`
2.  Variable names - E.g., `predictor_x`
3.  In-text R code - E.g., `here::here()`

### Setup: Load libraries

```{r}

library(tidyverse)
library(janitor)
library(here)         
library(estimatr)     
library(cowplot)   
library(jtools) # package with function `summ()`
library(gt)
library(gtsummary)
library(cardx)
library(performance)
```

Getting to know our data example - important variables

```{r}
variable_descriptions <- tribble(
  ~"Label", ~"Description",  
 #----------|-------------|,
  "zoneid" , "Zone or neighborhood ID: The observational unit (N=44)",   
  "waste_piles" , "The outcome variable (Y): The number of waste pile burns recorded (Range; 5, 125)",  
  "treat" , "The treatment assignment variable (0 = Control Group; 1 = Treatment Group)"
 )

gt(variable_descriptions) %>% 
    tab_header(title = "Important Variables"  # Add a title
  ) %>%
  tab_style(style = cell_text(weight = "bold"),
    locations = cells_column_labels()  # Make header row bold
  ) 
```

### Read in the Nansana data (Buntaine et al., 2024)

```{r data-in}

#waste pile count data:
counts_gpx <- read_csv(here("data", "waste_pile_counts_gpx.csv")) %>% 
    rename("waste_piles" = "total",
           "rain_0_48hrs" = "rf_0_to_48_hours",
           "rain_49_168hrs" = "rf_49_to_168_hours") %>% 
    filter(survey%in%c(
      "post_treatment_1","post_treatment_2","post_treatment_3",
      "post_treatment_4","post_treatment_5"))

#select subset of post-treatment periods (remove time point 5):
post_treat_subset <- counts_gpx %>% 
   filter(survey == "post_treatment_4")
```

# ------------------------------------------------------------------------------

### Model 1: Simple OLS estimator

Review of regression: Ordinary Least Squares (OLS)

# ------------------------------------------------------------------------------

```{r}

m1_ols <- lm(
    waste_piles ~ treat,
    data = post_treat_subset)

summ(m1_ols, model.fit = FALSE)
```

### Are we making reasonable assumptions?

-   Let's take a quick look at our outcome variable `waste piles`

```{r}
post_treat_subset %>%
  ggplot(aes(x = waste_piles)) +
  geom_histogram(binwidth = 5, fill = "blue", color = "white", alpha = 0.7) +
  labs(title = "Histogram Plot of Waste Piles",
    x = "Waste Piles (counts)",
    y = "Count") +
    theme_minimal()

```

**Check model assumption: normality of residuals**

QQ Plot: Studentized residuals v model fitted values

```{r}
check_model(m1_ols,  check = "qq" )

```

# ------------------------------------------------------------------------------

### Model 2: Relax- time to generalize!

-   Hmmm... our outcome is a count variable which brings into question whether OLS is a good fit for our data and whether the normality assumption is justified
-   No problem, let's do away with normality!
-   We can `relax` the normality assumption
-   Run a `generalized linear model` (GLM)
-   The outcome `waste_piles` is a `count variable`, not a true continuous variable
-   We can try out a common estimator used for count outcomes, the `Poisson regression model`

# ------------------------------------------------------------------------------

**Poisson Regression**

-   Explicitly model the outcome as a count variable
-   Assumes Y follows a Poisson distribution with discrete non-negative integers
-   Model assumes that the variance is proportional to the mean

Let's take a look at a Poisson distribution fitted over our data

```{r}

lambda_hat <- mean(post_treat_subset$waste_piles)

poisson_curve <- tibble(
  x = seq(0, max(post_treat_subset$waste_piles), by = 1),  # Range of x values
  density = dpois(seq(0, max(post_treat_subset$waste_piles), by = 1), lambda = lambda_hat) 
)

post_treat_subset %>% 
ggplot(aes(x = waste_piles)) +
  geom_histogram(aes(y = ..density..),
                 bins = 20, color = "black", fill = "lightblue") + 
  geom_line(data = poisson_curve, aes(x = x, y = density), color = "red", size = 1) +  # Poisson curve
  labs(
    title = "Histogram with Fitted Poisson Distribution",
    x = "Waste Pile Counts",
    y = "Density") +
  theme_minimal()
```

```{r}
m2_poisson <- glm(waste_piles ~ treat,
                  family = poisson(link = "log"),
                  data = post_treat_subset)

summ(m2_poisson, model.fit = FALSE)
```

**Intuition check:** The new estimate values look different...

-   The coefficients returned by `glm()` are now in the `log scale`
-   Notice in the GLM function we specified above we specified the distribution as, `family = poisson(link = "log")`
-   We can do a simple `log transformation` to get a similar result using OLS
-   Importantly, the resulting output when specifying the model in this way is super intuitive!

# ------------------------------------------------------------------------------

### Model 3: Simple is best! - the econometricians trick

# ------------------------------------------------------------------------------

-   Using the log transformation we can get *approximately* the same result (M2 & M3 models make slightly different assumptions)
-   We can model the outcome variable as the *natural log (ln)* transformation of waste piles counts
-   The estimate produced is conveniently interpreted as the `percent change in the outcome`!

```{r}

m3_log <- lm(
    log(waste_piles) ~ treat,
    data = post_treat_subset)

summ(m3_log, model.fit = FALSE)

export_summs(m2_poisson, m3_log,
             model.names = c("Poisson GLM","Log(Outcome) OLS"),
             statistics = "none")
```

So this estimate can be interpret as follows:

> *The model estimated that the treatment group had a 42% reduction in waste piles relative to the control group.*

-   This estimate, however, is still not a robust causal effect (the OLS estimator is still a bit naive)
-   Any ideas why this might be? - Discuss with you neighbor

# ------------------------------------------------------------------------------

Let's take a look at balance on the covariate Pre-Treatment Waste Pile Counts across treatment conditions

```{r}

post_treat_subset %>% 
    select(treat, waste_piles, pre_count_avg) %>% 
    tbl_summary(
        by = treat,
        statistic = list(all_continuous() ~ "{mean} ({sd})")) %>% 
    add_p() %>% 
    modify_header(label ~ "**Variable**") %>%
    modify_spanning_header(c("stat_1", "stat_2") ~ "**Treatment**") 
    #modify(title="Comparing balance of Covariates by Treatment Condition")
    
```

# ------------------------------------------------------------------------------

### Model 4: Moving towards casual inference

# ------------------------------------------------------------------------------

-   Is this experiment a `Randomized Controlled Trial (RCT)`?
-   Not quite - What about `selection bias`?
-   Recall that the experiment manually chose contiguous neighborhood pairs to compete in intervention
-   Selection bias (potential threat to causal inference):
-   The baseline number of pre-treatment waste piles may vary
-   Luckily, we can `control away` this potential selection bias by adding `pre_count_avg` to the OLS model!

```{r}

m4_control <- lm(
    log(waste_piles) ~ 
        treat +
        log(pre_count_avg),
    data = post_treat_subset)

summ(m4_control)

```

# ------------------------------------------------------------------------------

### Model 5: Does the enviroment stand still during our experiment?

# ------------------------------------------------------------------------------

No! We should account for events that might also affect trash burning during the treatment period

> I.e., Anything else that might affect the number of trash piles burned (besides our treatment)

-   Trash pile burning in these neighborhoods may vary by weather conditions
-   Note: We will also switch to using `heteroscedasticity robust` standard errors (*more on this later!*)

# ------------------------------------------------------------------------------

Look at balance across treatment conditions for average rain

```{r}

post_treat_subset %>% 
    select(treat, waste_piles, rain_0_48hrs, rain_49_168hrs) %>% 
    tbl_summary(
        by = treat,
        statistic = list(all_continuous() ~ "{mean} ({sd})")) %>% 
    add_p() %>% 
    modify_header(label ~ "**Variable**") %>%
    modify_spanning_header(c("stat_1", "stat_2") ~ "**Treatment**") 
    #modify(title="Comparing balance of Covariates by Treatment Condition")
    
```

```{r}

m5_control2 <- lm(
    log(waste_piles) ~ 
        treat +
        log(pre_count_avg) +
        rain_0_48hrs + rain_49_168hrs,
    data = post_treat_subset)

summ(m5_log_control2, robust = "HC2")

export_summs(m4_control, m5_control2, robust = "HC2",
             model.names = c("Model 4","Model 5"),
             statistics = "none")

```

# ------------------------------------------------------------------------------

### Model 6: Are neighborhoods `independent`?

-   We have another threat to causality, the neighborhoods were paired together
-   We have to account for this `paired data` feature which is called `clustered data`
-   **Why?** Clustered data violates the regression assumption that observations are `independent and identically distributed (i.i.d)`
-   In-other-words, the data has within group `dependencies`, paired neighborhoods will likely be more similar than un-paired neighborhoods
-   This structure of the data should be modeled

# ------------------------------------------------------------------------------

```{r}


m6_clust <- lm(
    log(waste_piles) ~ 
        treat +
        log(pre_count_avg) +
        rain_0_48hrs + rain_49_168hrs,
    data = post_treat_subset)

summ(m6_clust, robust = "HC2", cluster = "pair_id", model.fit = FALSE)

```

**Conclusion**

-   Our treatment effect result is `robust` (remains unchanged) to this standard error adjustment
-   **NOTE**: That the standard error (`SE`) is slightly more `conservative` (i.e., the SE increased)
-   After accounting for dependencies by pair clusters the `SE` increased by .01 (`SE_M5 = .06`; `SE_M6 = .07`).
-   However, our interpretation of the treatment effect remains unchanged. The treatment was found to reduce waste pile burning by 27% (a statistically significant result; `p<.001`).
-   This estimate has remained stable after accounting for pre-treatment waste piles

# ------------------------------------------------------------------------------
